{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX6uz33OsVxI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split,KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error,r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "fd2jllZ5sq7d",
        "outputId": "d72a62a7-40f2-47f1-8d7e-7bd95e489be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-45d496a0-5ef3-4fcc-8e12-fd5abd0ee946\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-45d496a0-5ef3-4fcc-8e12-fd5abd0ee946\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Khayet ANN AGMD revised.xlsx to Khayet ANN AGMD revised.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('Khayet ANN AGMD revised.xlsx')"
      ],
      "metadata": {
        "id": "YlZlJCyUswhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is named `df`\n",
        "# Extract the target column (assuming the last column is the target)\n",
        "target_column = df.columns[-1]  # Get the name of the last column\n",
        "flux_values = df[target_column]\n",
        "\n",
        "# Calculate the minimum, maximum, and range values\n",
        "min_flux = flux_values.min()\n",
        "max_flux = flux_values.max()\n",
        "range_flux = max_flux - min_flux\n",
        "\n",
        "# Print the results\n",
        "print(\"Minimum Flux:\", min_flux)\n",
        "print(\"Maximum Flux:\", max_flux)\n",
        "print(\"Range of Flux:\", range_flux)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62q57lJOILGQ",
        "outputId": "5ac48415-486a-4c37-9f81-c947e383a650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum Flux: 2.039\n",
            "Maximum Flux: 51.075\n",
            "Range of Flux: 49.036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[: , : -1]\n",
        "X= X.to_numpy()\n",
        "print(X.shape)\n",
        "\n",
        "y = df.iloc[: , -1]\n",
        "y = y.to_numpy()\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSDQT3UytCqS",
        "outputId": "d94fc91f-9bfe-4110-d3fd-822bfbbc0611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 4)\n",
            "(72,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size= 0.2 , random_state=42)\n",
        "kf = KFold (n_splits= 5 , shuffle = True , random_state=42)\n",
        "mse_list = []\n",
        "r2_list = []\n",
        "for train_indices,dev_indices in kf.split(X_train) :\n",
        "  X_train_fold,X_dev_fold = X_train[train_indices],X_train[dev_indices]\n",
        "  y_train_fold,y_dev_fold = y_train[train_indices],y_train[dev_indices]\n",
        "  scaler = StandardScaler()\n",
        "  X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
        "  X_dev_fold_scaled = scaler.transform(X_dev_fold)\n",
        "\n",
        "  model = Sequential([Dense(units = 64 , activation = 'relu' , input_shape= (X_train_fold_scaled.shape[1], )),\n",
        "                      Dense(units = 32 , activation = 'relu'),\n",
        "                      Dense(units = 16 , activation = 'relu'),\n",
        "                      Dense(units = 1 , activation = 'linear'),\n",
        "                      ])\n",
        "  model.compile(loss = 'mean_squared_error' , optimizer = tf.keras.optimizers.Adam(0.001))\n",
        "  model.fit(X_train_fold_scaled,y_train_fold, epochs = 800 , verbose = 0)\n",
        "  y_dev_fold_prediction = model.predict(X_dev_fold_scaled)\n",
        "  mse = mean_squared_error(y_dev_fold,y_dev_fold_prediction)\n",
        "  r2 = r2_score(y_dev_fold,y_dev_fold_prediction)\n",
        "  mse_list.append(mse)\n",
        "  r2_list.append(r2)\n",
        "mse_avrage = np.mean(mse_list)\n",
        "r2_avrage = np.mean(r2_list)\n",
        "print(f\" mse for all folds is {mse_list}, the avrage of them is {mse_avrage:.3f}\")\n",
        "print(f'and for r2 the list is {r2_list} and the average is {r2_avrage:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMetTl_QtGzb",
        "outputId": "a9069595-2975-454a-df1b-2c6b8c47ca46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7949a8493910> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            " mse for all folds is [5.227371506907859, 2.8770910391254536, 5.4280965233662135, 4.49015772740972, 4.295260101089364], the avrage of them is 4.464\n",
            "and for r2 the list is [0.9099130075174717, 0.9770148293864107, 0.7300885279784542, 0.9662361622583412, 0.9744024468901723] and the average is 0.912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential([Dense(units = 64 , activation = 'relu' , input_shape= (X_train.shape[1], )),\n",
        "                      Dense(units = 32 , activation = 'relu'),\n",
        "                      Dense(units = 16 , activation = 'relu'),\n",
        "                      Dense(units = 1 , activation = 'linear'),\n",
        "                      ])\n",
        "\n",
        "model.compile(loss = 'mean_squared_error' , optimizer = tf.keras.optimizers.Adam(0.001))\n",
        "model.fit(X_train_scaled,y_train, epochs = 800 , verbose = 0)\n",
        "\n",
        "\n",
        "# Evaluating the final model on the test set\n",
        "y_test_prediction = model.predict(X_test_scaled)\n",
        "mse_test = mean_squared_error(y_test, y_test_prediction)\n",
        "r2_test = r2_score(y_test, y_test_prediction)\n",
        "print(f'mse for the test is: {mse_test:.3f}')\n",
        "print(f'R^2 for the test is: {r2_test:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU1U2R99tG2O",
        "outputId": "d9a066ca-88e1-43b6-a72b-cfe8aff059e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7949a84905e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
            "mse for the test is: 4.885\n",
            "R^2 for the test is: 0.968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Calculate MAE for the test dataset\n",
        "mae_test = mean_absolute_error(y_test, y_test_prediction)\n",
        "\n",
        "# Print the MAE result\n",
        "print(f\"mae for test dataset is: {mae_test:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_OoqqmFtRcU",
        "outputId": "53ea87a4-7c07-492c-eae1-53566ab4ea96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae for test dataset is: 1.655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have the following variables already defined\n",
        "# y_test: actual target values for the test set\n",
        "# y_test_pred: predicted values for the test set\n",
        "# mae_test: mean absolute error calculated previously\n",
        "\n",
        "# Calculate MAE for the test dataset (if not already done)\n",
        "mae_test = mean_absolute_error(y_test, y_test_prediction)\n",
        "\n",
        "# Calculate the mean of the target values for the Relative MAE\n",
        "mean_target = np.mean(y_test)\n",
        "\n",
        "# Calculate Relative MAE for the test dataset\n",
        "relative_mae_test = (mae_test / mean_target) * 100\n",
        "\n",
        "# Print results\n",
        "print(f\"MAE for test dataset is: {mae_test:.3f}\")\n",
        "print(f\"Relative MAE for test dataset is: {relative_mae_test:.2f}%\")\n"
      ],
      "metadata": {
        "id": "QFMH1IYXt1V4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07048833-a506-442d-c254-ba45ec399c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE for test dataset is: 1.655\n",
            "Relative MAE for test dataset is: 4.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bPM5DV_kt34m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mPVbWiOt377"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_6yxw5C2t3-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U-pzSyq-t4By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BqlH-jRut4EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5WgrUAJ_t4Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CBCAxIm9t4KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5lbzX87Zt4NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJSceag5t4QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fnu2WmYyt4TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame and you have correctly extracted X and y\n",
        "# X and y have been verified as:\n",
        "# X.shape: (69, 5)\n",
        "# y.shape: (69,)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features (normalize)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'svr__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
        "    'svr__gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 'scale', 'auto'],\n",
        "    'svr__epsilon': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'pca__n_components': [2, 3, 4, 5]  # Adding PCA components as part of the grid search\n",
        "}\n",
        "\n",
        "# Create a pipeline with PCA and SVR\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', scaler),\n",
        "    ('pca', PCA()),\n",
        "    ('svr', SVR(kernel='rbf'))\n",
        "])\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model with optimized parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on training and testing sets\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance on training set\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "# Evaluate model performance on testing set\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Train Mean Squared Error:\", train_mse)\n",
        "print(\"Train R2 Score:\", train_r2)\n",
        "print(\"Test Mean Squared Error:\", test_mse)\n",
        "print(\"Test R2 Score:\", test_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScV3iiY3t4Yl",
        "outputId": "9b20f8aa-6ae7-403b-bf06-3cec067e4c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'pca__n_components': 4, 'svr__C': 10000, 'svr__epsilon': 0.0001, 'svr__gamma': 0.01}\n",
            "Train Mean Squared Error: 0.7396185625937599\n",
            "Train R2 Score: 0.9932129171934304\n",
            "Test Mean Squared Error: 3.1609340588731922\n",
            "Test R2 Score: 0.9795956070078662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "2240 fits failed out of a total of 8960.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "2240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 469, in fit\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\", line 474, in fit_transform\n",
            "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\", line 547, in _fit\n",
            "    return self._fit_full(X, n_components, xp, is_array_api_compliant)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\", line 561, in _fit_full\n",
            "    raise ValueError(\n",
            "ValueError: n_components=5 must be between 0 and min(n_samples, n_features)=4 with svd_solver='covariance_eigh'\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [-116.62929322 -116.62834932 -116.61950752 ...           nan           nan\n",
            "           nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Calculate MAE for the test dataset\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Print the MAE result\n",
        "print(f\"mae for test dataset is: {mae_test:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAxJwalcuKvR",
        "outputId": "d2a69432-59e4-400b-e2c6-fee86bdec4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae for test dataset is: 1.432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have the following variables already defined\n",
        "# y_test: actual target values for the test set\n",
        "# y_test_pred: predicted values for the test set\n",
        "# mae_test: mean absolute error calculated previously\n",
        "\n",
        "# Calculate MAE for the test dataset (if not already done)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Calculate the mean of the target values for the Relative MAE\n",
        "mean_target = np.mean(y_test)\n",
        "\n",
        "# Calculate Relative MAE for the test dataset\n",
        "relative_mae_test = (mae_test / mean_target) * 100\n",
        "\n",
        "# Print results\n",
        "print(f\"MAE for test dataset is: {mae_test:.3f}\")\n",
        "print(f\"Relative MAE for test dataset is: {relative_mae_test:.2f}%\")\n"
      ],
      "metadata": {
        "id": "mwXBkOyyuNwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81644fd2-541a-430b-d1a6-511bb7fa9e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE for test dataset is: 1.432\n",
            "Relative MAE for test dataset is: 4.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qY7nmR1MuNzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMXOiG6OuN24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OBDjMfOQuN5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rW56MwU6uN81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EK6VpcEAuOAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0HOh1rhhuObc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qivz1_NluOm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-ymHTchuOqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uoHr5FTruOtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q7T7tFS-uOvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizing features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Defining the XGBoost model with initial parameters\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "c\n",
        "\n",
        "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# **Identify the best model:**\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best model found through GridSearchCV:\", best_model)\n",
        "\n",
        "# Making predictions\n",
        "y_train_pred = best_model.predict(X_train_scaled)\n",
        "y_test_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation using MSE and R-squared on training and testing sets\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Training Mean Squared Error (MSE):\", train_mse)\n",
        "print(\"Training R-squared (R^2):\", train_r2)\n",
        "print(\"Test Mean Squared Error (MSE):\", test_mse)\n",
        "print(\"Test R-squared (R^2):\", test_r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOQojM2puOyy",
        "outputId": "34d59192-736e-4fd1-e0a8-bce90ab18407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model found through GridSearchCV: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "             gamma=None, grow_policy=None, importance_type=None,\n",
            "             interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
            "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
            "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
            "             num_parallel_tree=None, random_state=42, ...)\n",
            "Training Mean Squared Error (MSE): 0.3084839155803216\n",
            "Training R-squared (R^2): 0.9971692085820614\n",
            "Test Mean Squared Error (MSE): 2.582978440018169\n",
            "Test R-squared (R^2): 0.9833264135857591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Calculate MAE for the test dataset\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Print the MAE result\n",
        "print(f\"mae for test dataset is: {mae_test:.3f}\")\n"
      ],
      "metadata": {
        "id": "4MhHHFqyuh0I",
        "outputId": "cd2c9918-e14a-4646-cb92-00e707b22c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae for test dataset is: 1.395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have the following variables already defined\n",
        "# y_test: actual target values for the test set\n",
        "# y_test_pred: predicted values for the test set\n",
        "# mae_test: mean absolute error calculated previously\n",
        "\n",
        "# Calculate MAE for the test dataset (if not already done)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Calculate the mean of the target values for the Relative MAE\n",
        "mean_target = np.mean(y_test)\n",
        "\n",
        "# Calculate Relative MAE for the test dataset\n",
        "relative_mae_test = (mae_test / mean_target) * 100\n",
        "\n",
        "# Print results\n",
        "print(f\"MAE for test dataset is: {mae_test:.3f}\")\n",
        "print(f\"Relative MAE for test dataset is: {relative_mae_test:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6_f931AI0fc",
        "outputId": "2b690d0b-320e-4dfa-a94c-4e50bcf23435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE for test dataset is: 1.395\n",
            "Relative MAE for test dataset is: 4.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k7swY3gAJBK0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
