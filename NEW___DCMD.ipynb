{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZRefBEUikE_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split,KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error,r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6NEmU0K4aGXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "K1a88qmTiuGw",
        "outputId": "21ee63dd-5afc-4f25-d095-4d5f82bf2f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d0cb5b2f-b0e8-4443-a742-3999d0296e0c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d0cb5b2f-b0e8-4443-a742-3999d0296e0c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving updated - Copy.xlsx to updated - Copy.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"updated - Copy.xlsx\")"
      ],
      "metadata": {
        "id": "31uhuJUJkT7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mfgz2o0Haklp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for numerical columns (range, mean, etc.)\n",
        "numerical_summary = df.describe().T\n",
        "numerical_summary['Range'] = numerical_summary['max'] - numerical_summary['min']\n",
        "numerical_summary = numerical_summary[['min', 'max', 'mean', 'std', 'Range']]\n",
        "print(\"Numerical Summary:\\n\", numerical_summary)\n",
        "\n",
        "# Unique levels for each column\n",
        "unique_counts = df.nunique()\n",
        "print(\"\\nUnique Levels in Each Column:\\n\", unique_counts)\n",
        "\n",
        "# Data types to identify categorical and numerical features\n",
        "print(\"\\nData Types:\\n\", df.dtypes)\n",
        "\n",
        "# Distribution analysis for numerical features\n",
        "for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
        "    print(f\"\\n{column} Value Counts:\\n\", df[column].value_counts(bins=5))  # Binned count to view ranges\n",
        "\n",
        "# Count of unique values for each categorical feature\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "for column in categorical_columns:\n",
        "    print(f\"\\n{column} Levels:\\n\", df[column].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw7O1VUNakol",
        "outputId": "04307bf1-c7ab-4a55-85d5-10ab61de1d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical Summary:\n",
            "                              min        max       mean        std      Range\n",
            "Tc                      5.000000  25.000000  18.043478   7.822356  20.000000\n",
            "inlet feed temprature  40.000000  90.000000  67.391304  17.460222  50.000000\n",
            "feed salinity           2.000000  43.000000  19.826087  20.473768  41.000000\n",
            "feed flow rate          2.500000   4.650000   4.434783   0.551289   2.150000\n",
            "coolant flow rate       2.000000   3.650000   3.473913   0.483295   1.650000\n",
            "flux                   10.832712  97.352766  50.241077  24.536088  86.520054\n",
            "\n",
            "Unique Levels in Each Column:\n",
            " Tc                        5\n",
            "inlet feed temprature     6\n",
            "feed salinity             2\n",
            "feed flow rate            4\n",
            "coolant flow rate         3\n",
            "flux                     69\n",
            "dtype: int64\n",
            "\n",
            "Data Types:\n",
            " Tc                         int64\n",
            "inlet feed temprature      int64\n",
            "feed salinity              int64\n",
            "feed flow rate           float64\n",
            "coolant flow rate        float64\n",
            "flux                     float64\n",
            "dtype: object\n",
            "\n",
            "Tc Value Counts:\n",
            " (21.0, 25.0]    33\n",
            "(4.979, 9.0]    12\n",
            "(13.0, 17.0]    12\n",
            "(9.0, 13.0]      6\n",
            "(17.0, 21.0]     6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "inlet feed temprature Value Counts:\n",
            " (39.949000000000005, 50.0]    22\n",
            "(80.0, 90.0]                  17\n",
            "(60.0, 70.0]                  14\n",
            "(50.0, 60.0]                   8\n",
            "(70.0, 80.0]                   8\n",
            "Name: count, dtype: int64\n",
            "\n",
            "feed salinity Value Counts:\n",
            " (1.9580000000000002, 10.2]    39\n",
            "(34.8, 43.0]                  30\n",
            "(10.2, 18.4]                   0\n",
            "(18.4, 26.6]                   0\n",
            "(26.6, 34.8]                   0\n",
            "Name: count, dtype: int64\n",
            "\n",
            "feed flow rate Value Counts:\n",
            " (4.22, 4.65]                  61\n",
            "(2.4970000000000003, 2.93]     4\n",
            "(3.36, 3.79]                   4\n",
            "(2.93, 3.36]                   0\n",
            "(3.79, 4.22]                   0\n",
            "Name: count, dtype: int64\n",
            "\n",
            "coolant flow rate Value Counts:\n",
            " (3.32, 3.65]     60\n",
            "(1.997, 2.33]     6\n",
            "(2.66, 2.99]      3\n",
            "(2.33, 2.66]      0\n",
            "(2.99, 3.32]      0\n",
            "Name: count, dtype: int64\n",
            "\n",
            "flux Value Counts:\n",
            " (10.745000000000001, 28.137]    16\n",
            "(28.137, 45.441]                16\n",
            "(62.745, 80.049]                16\n",
            "(45.441, 62.745]                13\n",
            "(80.049, 97.353]                 8\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for column in df.columns:\n",
        "    print(f\"Unique values in {column}:\\n\", df[column].unique(), \"\\n\")"
      ],
      "metadata": {
        "id": "TLp6J7dtdDcE",
        "outputId": "fd15cb24-74db-4ff4-fbdc-16acacb817e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in Tc:\n",
            " [ 5 10 15 20 25] \n",
            "\n",
            "Unique values in inlet feed temprature:\n",
            " [40 50 60 70 80 90] \n",
            "\n",
            "Unique values in feed salinity:\n",
            " [ 2 43] \n",
            "\n",
            "Unique values in feed flow rate:\n",
            " [4.6  4.65 2.5  3.5 ] \n",
            "\n",
            "Unique values in coolant flow rate:\n",
            " [3.65 2.   2.9 ] \n",
            "\n",
            "Unique values in flux:\n",
            " [24.51602776 37.91709896 51.54711087 64.2671026  80.1735049  96.99299013\n",
            " 18.87789873 32.83746913 47.95754124 66.32588634 81.90959324 92.85331436\n",
            " 17.52177829 29.12520553 48.892151   61.10782146 76.3855342  89.82486484\n",
            " 17.31242839 30.72202952 45.06099869 60.14320304 73.73867778 89.37876219\n",
            " 11.47634218 26.13665263 36.67713193 48.34120155 66.37182054 75.226452\n",
            " 23.78596988 36.97331147 50.9490085  65.97882809 79.69173997 97.35276577\n",
            " 10.83271209 18.23057999 30.89123304 44.60489041 57.26517072 74.39988072\n",
            " 16.91479052 28.78634263 46.44662293 60.68622335 76.24161324 90.21880125\n",
            " 14.7555093  16.77725118 19.17223339 34.09172093 35.73459716 43.6272097\n",
            " 53.99721546 60.         72.06322866 18.29896907 20.10309278 21.13402062\n",
            " 42.5257732  43.81443299 44.84536082 73.71134021 74.48453608 75.77319588\n",
            " 51.52654164 66.65448188 73.67450731] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NFH9GOagdDfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZJytYSuNdDiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eVJrdkCddDlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Khs_P9XXdDn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HcSBSaSKdDqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LCTrqt2edDtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i2DrgTrydDwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract the target column\n",
        "target_column = df.columns[-1]  # Get the name of the last column\n",
        "flux_values = df[target_column]\n",
        "\n",
        "# Calculate the minimum, maximum, and range values\n",
        "min_flux = flux_values.min()\n",
        "max_flux = flux_values.max()\n",
        "range_flux = max_flux - min_flux\n",
        "\n",
        "\n",
        "print(\"Minimum Flux:\", min_flux)\n",
        "print(\"Maximum Flux:\", max_flux)\n",
        "print(\"Range of Flux:\", range_flux)\n"
      ],
      "metadata": {
        "id": "1qOpW-YDJFzC",
        "outputId": "0820bcb5-36e1-41df-cb0c-f8391656690e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum Flux: 10.8327120918443\n",
            "Maximum Flux: 97.3527657671089\n",
            "Range of Flux: 86.5200536752646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Extract features and target from DataFrame\n",
        "X = df.iloc[:, :-1].to_numpy()\n",
        "y = df.iloc[:, -1].to_numpy()\n",
        "\n",
        "# Verify the shapes of X and y\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"y.shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA55ghNZkUFa",
        "outputId": "76a8ec80-a97a-4ece-90b4-1de6940cc8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape: (69, 5)\n",
            "y.shape: (69,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uXuuMawEkjrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xY-ER4FmkjuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AL2jHy9Gkjx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is going to search for the best structure using cross validation\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size= 0.2 , random_state=42)\n",
        "kf = KFold (n_splits= 5 , shuffle = True , random_state=42)\n",
        "mse_list = []\n",
        "r2_list = []\n",
        "for train_indices,dev_indices in kf.split(X_train) :\n",
        "  X_train_fold,X_dev_fold = X_train[train_indices],X_train[dev_indices]\n",
        "  y_train_fold,y_dev_fold = y_train[train_indices],y_train[dev_indices]\n",
        "  scaler = StandardScaler()\n",
        "  X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
        "  X_dev_fold_scaled = scaler.transform(X_dev_fold)\n",
        "\n",
        "  model = Sequential([Dense(units = 64 , activation = 'relu' , input_shape= (X_train_fold_scaled.shape[1], )),\n",
        "                      Dense(units = 32 , activation = 'relu'),\n",
        "                      Dense(units = 16 , activation = 'relu'),\n",
        "                      Dense(units = 1 , activation = 'linear'),\n",
        "                      ])\n",
        "  model.compile(loss = 'mean_squared_error' , optimizer = tf.keras.optimizers.Adam(0.001))\n",
        "  model.fit(X_train_fold_scaled,y_train_fold, epochs = 800 , verbose = 0)\n",
        "  y_dev_fold_prediction = model.predict(X_dev_fold_scaled)\n",
        "  mse = mean_squared_error(y_dev_fold,y_dev_fold_prediction)\n",
        "  r2 = r2_score(y_dev_fold,y_dev_fold_prediction)\n",
        "  mse_list.append(mse)\n",
        "  r2_list.append(r2)\n",
        "mse_avrage = np.mean(mse_list)\n",
        "r2_avrage = np.mean(r2_list)\n",
        "print(f\" mse for all folds is {mse_list}, the avrage of them is {mse_avrage:.3f}\")\n",
        "print(f'and for r2 the list is {r2_list} and the average is {r2_avrage:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSKX3gT5kkaH",
        "outputId": "97766762-28d1-4924-b6d7-ecf642c9e67c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dd2a8f6f7f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
            " mse for all folds is [15.011268822770017, 4.054454614308049, 15.323447088673525, 26.50286118608766, 5.697584806305143], the avrage of them is 13.318\n",
            "and for r2 the list is [0.9617689887645825, 0.9946632982830148, 0.8842218939499483, 0.9689701414077484, 0.9898593891581382] and the average is 0.960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from"
      ],
      "metadata": {
        "id": "cMaEaydtnMiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Above, we have chosen the best structure of our neural network based on it's performance on the kfold or cross validation\n",
        "# Here , we will train our model using the selected ANN though with all of the training set not the folds and evaluate on the test set\n",
        "\n",
        "# Scaling the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Building the model with L2 regularization\n",
        "model = Sequential([\n",
        "    Dense(units=64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.01)),\n",
        "    Dense(units=32, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dense(units=16, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dense(units=1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train_scaled, y_train, epochs=800, verbose=0)\n",
        "\n",
        "# Evaluating the final model on the test set\n",
        "y_train_prediction = model.predict(X_train_scaled)\n",
        "mse_train = mean_squared_error(y_train, y_train_prediction)\n",
        "r2_train = r2_score(y_train, y_train_prediction)\n",
        "\n",
        "y_test_prediction = model.predict(X_test_scaled)\n",
        "mse_test = mean_squared_error(y_test, y_test_prediction)\n",
        "r2_test = r2_score(y_test, y_test_prediction)\n",
        "\n",
        "# Printing the evaluation metrics\n",
        "print(f'mse for the train is: {mse_train:.3f}')\n",
        "print(f'R^2 for the train is: {r2_train:.2f}')\n",
        "print(f'mse for the test is: {mse_test:.3f}')\n",
        "print(f'R^2 for the test is: {r2_test:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpjHnQ9AnQEB",
        "outputId": "f83e7cc2-0c19-4970-b727-b0a9d68ace2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dd2a8f6c4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
            "mse for the train is: 2.071\n",
            "R^2 for the train is: 1.00\n",
            "mse for the test is: 6.246\n",
            "R^2 for the test is: 0.992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Calculate MAE for the test dataset\n",
        "mae_test = mean_absolute_error(y_test, y_test_prediction)\n",
        "\n",
        "# Print the MAE result\n",
        "print(f\"mae for test dataset is: {mae_test:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XwjL5bynSTe",
        "outputId": "52cc253f-7109-4df8-b0b8-fcaa170db036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae for test dataset is: 1.979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# y_test: actual target values for the test set\n",
        "# y_test_pred: predicted values for the test set\n",
        "# mae_test: mean absolute error calculated previously\n",
        "\n",
        "# Calculate MAE for the test dataset\n",
        "mae_test = mean_absolute_error(y_test, y_test_prediction)\n",
        "\n",
        "# Calculate the mean of the target values for the Relative MAE\n",
        "mean_target = np.mean(y_test)\n",
        "\n",
        "# Calculate Relative MAE for the test dataset\n",
        "relative_mae_test = (mae_test / mean_target) * 100\n",
        "\n",
        "# Print results\n",
        "print(f\"MAE for test dataset is: {mae_test:.3f}\")\n",
        "print(f\"Relative MAE for test dataset is: {relative_mae_test:.2f}%\")\n"
      ],
      "metadata": {
        "id": "rWkef89qn0A8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ab45e1-9ae0-44a4-84f3-3d90963b4842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE for test dataset is: 1.979\n",
            "Relative MAE for test dataset is: 3.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oRSIkKXLn0Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w8WOkNUBn0Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8u5DDYUVn0J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CvZiYo_Xn0Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xi75YRubn0Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# X and y have been verified as:\n",
        "# X.shape: (69, 5)\n",
        "# y.shape: (69,)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features (normalize)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'svr__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
        "    'svr__gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 'scale', 'auto'],\n",
        "    'svr__epsilon': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'pca__n_components': [2, 3, 4, 5]  # Adding PCA components as part of the grid search\n",
        "}\n",
        "\n",
        "# Create a pipeline with PCA and SVR\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', scaler),\n",
        "    ('pca', PCA()),\n",
        "    ('svr', SVR(kernel='rbf'))\n",
        "])\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model with optimized parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on training and testing sets\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance on training set\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "# Evaluate model performance on testing set\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Train Mean Squared Error:\", train_mse)\n",
        "print(\"Train R2 Score:\", train_r2)\n",
        "print(\"Test Mean Squared Error:\", test_mse)\n",
        "print(\"Test R2 Score:\", test_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npo_0dFsn0Sb",
        "outputId": "6209ae94-d3e1-49f2-f07d-6143aad2442e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'pca__n_components': 4, 'svr__C': 10000, 'svr__epsilon': 1, 'svr__gamma': 0.01}\n",
            "Train Mean Squared Error: 3.588724568034491\n",
            "Train R2 Score: 0.9934715097449378\n",
            "Test Mean Squared Error: 4.462107355995473\n",
            "Test R2 Score: 0.9939855288687178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Calculate MAE for the test dataset\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Print the MAE result\n",
        "print(f\"mae for test dataset is: {mae_test:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4lgTYPon0VJ",
        "outputId": "d62fa604-be38-415f-8a2c-7a47075f3118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae for test dataset is: 1.729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# y_test: actual target values for the test set\n",
        "# y_test_pred: predicted values for the test set\n",
        "# mae_test: mean absolute error calculated previously\n",
        "\n",
        "# Calculate MAE for the test dataset (if not already done)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Calculate the mean of the target values for the Relative MAE\n",
        "mean_target = np.mean(y_test)\n",
        "\n",
        "# Calculate Relative MAE for the test dataset\n",
        "relative_mae_test = (mae_test / mean_target) * 100\n",
        "\n",
        "# Print results\n",
        "print(f\"MAE for test dataset is: {mae_test:.3f}\")\n",
        "print(f\"Relative MAE for test dataset is: {relative_mae_test:.2f}%\")\n"
      ],
      "metadata": {
        "id": "zUTaBhEvn0YE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e92123c-693e-40c7-f32b-21bfeb240ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE for test dataset is: 1.729\n",
            "Relative MAE for test dataset is: 3.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OFo8gqK1n0ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z4aOnAULn0d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g7dALj2-n0ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-_dGxcjYoEmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K2qIVKyDoEpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SJ0kJKa_oEsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Cz83-HNoEu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7MMkjDC-oExx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c3TWcBWLoE0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizing features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Defining the XGBoost model with initial parameters\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# **Identify the best model:**\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best model found through GridSearchCV:\", best_model)\n",
        "\n",
        "# Making predictions\n",
        "y_train_pred = best_model.predict(X_train_scaled)\n",
        "y_test_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation using MSE and R-squared on training and testing sets\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Training Mean Squared Error (MSE):\", train_mse)\n",
        "print(\"Training R-squared (R^2):\", train_r2)\n",
        "print(\"Test Mean Squared Error (MSE):\", test_mse)\n",
        "print(\"Test R-squared (R^2):\", test_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QCovCcVoE3g",
        "outputId": "acd33e8c-e85c-4274-bb14-6d5851d2b6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model found through GridSearchCV: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "             gamma=None, grow_policy=None, importance_type=None,\n",
            "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
            "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
            "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "             multi_strategy=None, n_estimators=300, n_jobs=None,\n",
            "             num_parallel_tree=None, random_state=42, ...)\n",
            "Training Mean Squared Error (MSE): 0.4884531874135627\n",
            "Training R-squared (R^2): 0.9991114219512728\n",
            "Test Mean Squared Error (MSE): 4.2271599202018235\n",
            "Test R-squared (R^2): 0.994302214339777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Calculate MAE for the test dataset\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Print the MAE result\n",
        "print(f\"mae for test dataset is: {mae_test:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxfzPeCVoFB7",
        "outputId": "90ee08fd-3e44-4848-fcee-8eca3ea804f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae for test dataset is: 1.677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# y_test: actual target values for the test set\n",
        "# y_test_pred: predicted values for the test set\n",
        "# mae_test: mean absolute error calculated previously\n",
        "\n",
        "# Calculate MAE for the test dataset (if not already done)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Calculate the mean of the target values for the Relative MAE\n",
        "mean_target = np.mean(y_test)\n",
        "\n",
        "# Calculate Relative MAE for the test dataset\n",
        "relative_mae_test = (mae_test / mean_target) * 100\n",
        "\n",
        "# Print results\n",
        "print(f\"MAE for test dataset is: {mae_test:.3f}\")\n",
        "print(f\"Relative MAE for test dataset is: {relative_mae_test:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZBC3RPHG3Fu",
        "outputId": "d37c6dac-36ca-49ae-a7f0-2f90b760d268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE for test dataset is: 1.677\n",
            "Relative MAE for test dataset is: 3.08%\n"
          ]
        }
      ]
    }
  ]
}